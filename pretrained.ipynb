{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /Users/daniel/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|██████████| 170M/170M [02:54<00:00, 1.02MB/s]   \n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained = True)\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# load coco categories\n",
    "COCO_CLASS_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coloured_mask(mask):\n",
    "    # 10 colours\n",
    "    colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    r[mask == 1], g[mask == 1], b[mask == 1] = colours[random.randrange(0,10)]\n",
    "    coloured_mask = np.stack([r, g, b], axis=2)\n",
    "    return coloured_mask\n",
    "\n",
    "\n",
    "def get_prediction(img_path, confidence):\n",
    "    #img = Image.open(img_path)\n",
    "    img = Image.fromarray(img_path)\n",
    "    #print(type(img))\n",
    "    \n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x>confidence][-1]\n",
    "    masks = (pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "    # print(pred[0]['labels'].numpy().max())\n",
    "    pred_class = [COCO_CLASS_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class\n",
    "\n",
    "\n",
    "def segment_instance(img_path, confidence = 0.5, rect_th = 2, text_size = 1.5, text_th = 2):\n",
    "    masks, boxes, pred_cls = get_prediction(img_path, confidence)\n",
    "    #####   #####   #####   #####   #####\n",
    "    # img = cv2.imread(img_path)\n",
    "    img = img_path\n",
    "    #####   #####   #####   #####   #####\n",
    "\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(masks)):\n",
    "        rgb_mask = get_coloured_mask(masks[i])\n",
    "        img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
    "        cv2.rectangle(img, \n",
    "                        (int(boxes[i][0][0]), int(boxes[i][0][1])), \n",
    "                        (int(boxes[i][1][0]), int(boxes[i][1][1])), \n",
    "                        color = (0, 255, 0), \n",
    "                        thickness = rect_th)\n",
    "        # cv2.rectangle(img, boxes[i][0], boxes[i][1], color = (0, 255, 0), thickness = rect_th)\n",
    "        cv2.putText(img, \n",
    "                    pred_cls[i], \n",
    "                    (int(boxes[i][0][0]), int(boxes[i][0][1])),\n",
    "                    # boxes[i][0], \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    text_size, \n",
    "                    (0,255,0), \n",
    "                    thickness = text_th)\n",
    "    #plt.figure(figsize=(20,30))\n",
    "    #plt.imshow(img)\n",
    "    #plt.xticks([])\n",
    "    #plt.yticks([])\n",
    "    #plt.show()\n",
    "    return img\n",
    "\n",
    "# segment_instance('./traffic.jpg', confidence=0.7)\n",
    "# segment_instance('./examples/prova.jpg', confidence=0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2089/2089 [1:57:54<00:00,  3.39s/it] \n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture('./examples/FSD.mp4')\n",
    "#success, image = vidcap.read()\n",
    "# print(vidcap.get(cv2.CAP_PROP_FPS)) # fps\n",
    "\n",
    "success = True\n",
    "count = 0\n",
    "frames_class = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "for ele in tqdm(range(int(vidcap.get(7)))):\n",
    "    if success:\n",
    "        success, image = vidcap.read()\n",
    "        frames_class.append(segment_instance(image, confidence=0.7))\n",
    "        count += 1\n",
    "    else:\n",
    "        print(f'something went wrong in {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"test_d\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(frames_class, fp)\n",
    "\n",
    "#>>> with open(\"test\", \"rb\") as fp:   # Unpickling\n",
    "#...   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2089/2089 [00:09<00:00, 228.15it/s]\n"
     ]
    }
   ],
   "source": [
    "height, width, layers = frames_class[0].shape\n",
    "\n",
    "final_video = cv2.VideoWriter('final.avi', 0, 30, (width, height))\n",
    "\n",
    "for image in tqdm(frames_class):\n",
    "    final_video.write(image)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "final_video.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a31dc52f2a15ebec876b164bc087f10e745d79bfabeaaf6c6832eed247a2811"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
